---
layout: post
permalink: /bdd-notes.html
title: üè´ MOOC Relational Databases ‚Äì notes
author: Fr√©d√©ric Bardolle
---

My notes from the [Relational Databases class](https://www.fun-mooc.fr/courses/inria/41008/session01/), taught by Serge Abiteboul, Benjamin Nguyen and Philippe Rigaux from Inria on FUN.

## Semaine 1 : Transactions et concurrence

### 1. Introduction : les transactions

* Propri√©t√©s des transactions ACID :
    * Atomicit√©
    * Coh√©rence (garantie par le programmeur, √† la diff√©rence des autres propri√©t√©s qui sont garanties par le syst√®me)
    * Isolation
    * Durabilit√©
* COMMIT : valider une transaction
* ROLLBACK : annuler une transaction
* Une transaction : ensemble s√©quentiel d‚Äôop√©rations permettant de passer d‚Äôun √©tat coh√©rent de la base √† un autre √©tat coh√©rent.

### 2. Les probl√®mes

* Probl√®mes d‚Äôincoh√©rence : lorsque plusieurs utilisateurs effectuent des op√©rations conflictuelles
* Anomalie de lecture non reproductible
    * Lecture et √©criture de nuplets identiques
    * Lecture, modif, lecture
* Anomalie de lecture fant√¥me
    * Agr√©gation, insertion, Agr√©gation
* √âcriture de nuplets identiques : l‚Äôordre importe

### 3. S√©rialisabilit√©

* La s√©rialisabilit√© permet de r√©pondre au probl√®me de l‚Äôisolation dans le cas de transaction qui s‚Äôenchev√™trent
* Un ordonnancement est suite d‚Äôop√©rations de plusieurs transactions, i.e. op√©rations de type lecture ou √©criture.
* Ordonnancement s√©rialisable si le graphe de pr√©c√©dence est sans circuit (graphe acyclique dirig√©e).
* Pour r√©soudre √ßa : estampillage (curatif) ou verrouillage (pr√©ventif)

### 4. Estampillage

* On attribue une estampille √† chaque transaction suivant sa date de d√©but.
* Probl√®me : abandon en cascade, risques de privation pour les transactions longues
* Ew(D)>Er(D)

###  5. Verrouillage √† 2 phases

* Deux types de verrous : partag√© (S) et exclusif (X)
* Les *read* (R) tentent de cr√©er des S, les *write* (W) tentent de cr√©er des X
* Probl√®me : les *deadlocks*, o√π deux transactions se bloquent mutuellement
* Pour y rem√©dier :
    * *wait-die* : la transaction la plus vieille est mise en attente, la plus r√©cente est annul√©e.
    * *wound-wait* : la transaction la plus vieille est annul√©e, la plus r√©cente est mise en attente.
* La s√©rialisabilit√© co√ªte cher en terme de performance. Solutions :
    * Tol√©rer un certain nombre d‚Äôanomalie : degr√© d‚Äôisolation
    * Verrouiller autrement : verrouillage hi√©rarchique

### 6. Degr√©s d'isolation dans les SGBD

L‚Äôisolation autorise a transgresser la s√©rialisabilit√© pour gagner en performance.
4 niveaux : 

* S√©rialisable ‚Äî> SERIALIZABLE : s√©rialisabilit√© compl√®te assur√©e, donn√©es verrouill√©es.
* Lectures reproductibles ‚Äî> REPEATABLE READ : lectures reproductibles mais requ√™tes non-reproductibles. Apparition de fant√¥mes (*phantom read*).
* Lectures valides (propres) ‚Äî> READ COMMITED : lectures et requ√™tes non-reproductibles. Apparition de fant√¥mes et changement de valeurs d√©j√† lues.
* Lectures d√©grad√©es ‚Äî> READ UNCOMMITED : lectures et requ√™tes non-reproductibles. Lectures sales (*dirty read*) i.e. sur des donn√©es non commit√©e.

* RC (par d√©faut Oracle) : beaucoup de lecture, peu d‚Äô√©criture, transactions longues, peu de transactions
* S ou RR (par d√©faut MySQL sur table InnoDB) : peu de lecture, peu d‚Äô√©criture, transactions courtes, beaucoup de transactions
* RU : d√©bug

### 7. Verrouillage hi√©rarchique
Autre mani√®re d‚Äôam√©liorer les performances. Le verrouillage est une op√©ration O(n) avec n nombre de nuplets.

L‚Äôid√©e est d‚Äôadapter la taille du verrou au nombre de transaction.

Nouveaux types de verrou : row share (RS) et row exclusive (RX). Ces verrous sont pos√©s au niveau de la table, et au niveau de la ligne.

Si la d√©cision est NON au niveau table, c‚Äôest rapide. Si c‚Äôest OUI, on valide sur la ligne, et c‚Äôest pareil qu‚Äôavant.

* RS (explicite) : toute les lectures de la table sont autoris√©es, toutes les modifications sont autoris√©es sauf la ligne verrouill√©e. *Exemple : on va lire quelques nuplets sur la table, on bloque les personnes qui souhaiterait modifier l‚Äôint√©gralit√© des donn√©es.*
* RX (implicite) : permet RS et RX, emp√™che S et X sur les nuplets. *Exemple : on veut modifier des donn√©es de la table, on bloque les personnes qui souhaiterait lire l‚Äôensemble de la table.*
* SRX (share row exclusive) : un S et un RX en m√™me temps, permet RS. Moins permissif que S. *Exemple : on va lire certaines donn√©es de la table, on ne bloque rien √† part des personnes qui souhaiterait modifier la table.*


## Semaine 2 : Indexation

### 1. Introduction

Le but : acc√®s √† de gros volumes de donn√©es. Pour cela : syst√®me de fichiers ou SGBD.


Pour les syst√®mes de fichiers, on peut acc√©l√©rer gr√¢ce √† la compression, √† la fragmentation, ou au partage du fichier en blocs.

On peut garder plusieurs blocs en m√©moire dans un *buffer*. Exemple de strat√©gie de remplacement des blocs : LRU (*least recently used*).

*Clustering* (regroupement) : on regroupe dans un m√™me bloc des donn√©es souvent utilis√©es ensemble.

### 2. Hi√©rarchie de m√©moire

Plusieurs crit√®res de stockage : d√©bit, taille et co√ªt.

M√©moire RAM (*random access memory*) :

* Semi-conducteur
* Tr√®s rapide (acc√®s micro-secondes)
* Volatile, petite et ch√®re

Disque :

* Lent (acc√®s milli-secondes)
* Persistantes, massive et bon march√©

Bande magn√©tique :

* Encore plus lent, mais encore plus massive

Flash :

* Semi-conducteur
* Plus rapide qu‚Äôun disque, moins cher que la RAM
* Persistant

On aimerait une grande base de donn√©es rapide et bon march√©. Pour cela, on m√©lange les diff√©rents types de m√©moire.

### 3. Fichiers index√©s

Un fichier index√© est une s√©quence de nuplets (ou enregistrement).

Un index sur un des attributs des nuplets permet un acc√®s direct.

Acc√®s s√©quentiel :

* Taille fixe : insertion en fin de fichier, suppression co√ªteuse (r√©solu avec un bit qui indique qu‚Äôun nuplet est vide)
* Taille variable : probl√®me de fragmentation ‚Äî> solution hybride (taille fixe + d√©bordement)

Acc√®s direct, trouver un nuplet :

* Parcourir le fichier (lecture de N/2 en moyenne)
* Divide and conquer (lecture de log(N) en moyenne)
* Utiliser un index (on garde cette structure en m√©moire)

Fichiers index√©s (non dense) :

* Fichier tri√© selon un attribut
* On construit un index pour cet attribut
* Lecture : un seul bloc
* Insertion : rien √† faire
* Suppression rien √† faire

Fichier index√© (dense) :

* Fichier non tri√© selon l‚Äôordre de l‚Äôattribut
* Un adresse de nuplet par valeur
* Lecture : au pire un bloc pour chaque nuplet
* Insertion : ins√©rer la cl√© de l‚Äôindex
* Suppression : supprimer la cl√© de l'index

¬´ Ce n'est pas chaque bloc qui est r√©f√©renc√© par un index, mais chaque enregistrement. Un bloc sera donc r√©f√©renc√© plusieurs fois. ¬ª

### 4. Arbre-B

Le principe : le fichier est d√©coup√© en bloc ; on a des index et aussi des index d‚Äôindex.

* n≈ìud de l'arbre (une boite en vert avec 7 compartiments)
* adresse ou pointeur (arc en bleu) : permet de passer d'un n≈ìud √† un autre jusqu'√† arriver √† un bloc de donn√©es
* cl√© : une valeur qui d√©termine l'enregistrement que l'on cherche. L'animation montre comment r√©cup√©rer l'enregistrement de cl√© 55.
* bloc de donn√©es (boite bleue) : contient des enregistrements

Pour une recherche de cl√© : descente en O(log(n))

Avantage : on peut faire des requ√™tes d‚Äôintervalles.

Si arbre d√©s√©quilibr√© : descente en O(n). ‚Äî> √† chaque acc√®s on essaie de r√©√©quilibrer l‚Äôarbre.

### 5. Hachage

Table de hachage (al√©atoire) T[1..N] : N pointeurs vers N blocs.

Fonction de hachage H : le nuplet de cl√© K est g√©r√© par le bloc T(H(K)).

Exemple : on veut ajouter l‚Äôenregistrement lili. Si H(lili)=2, on met lili dans le bloc 2.

On ajoute des enregistrements jusque‚Äô√† que les blocs soient pleins.

Si le bloc est plein (d√©bordement), on chaine.

Pas trop de probl√®me de d√©bordement (marche bien) avec un taux de remplissage de 60%.

### 6. Hachage dynamique

La table de hachage a une taille variable (1, 2, 4, 8, ‚Ä¶).

Quand un bloc est plein, il √©clate et on augmente la taille de la table.

Bonne performance. Travail pour double la taille de la table (mais pas sur disque). Pour amortir ce travail : hachage lin√©aire.


¬´  Lorsque je dois ins√©rer un n-uplet, je n'ai "rien √† faire" tant que la fonction de hashage donne un r√©sultat pointant vers un bloc qui n'est pas plein. Dans le cas contraire : - soit plusieurs r√©sultats de la table de hashage pointent vers le bloc et il n'y a qu‚Äô√† √©clater ; - soit il n'y a qu'un r√©sultat de la table de hashage et je dois doubler la taille de la table de hashage avant d'√©clater. Il y a donc pas n√©cessairement doublement de la taille de hashage √† chaque fois qu'il y a √©clatement d'un bloc.

Par ailleurs, lorsque j'√©clate un bloc, il est possible qu'une partie des n-uplet de ce bloc soit √† d√©placer dans le nouveau bloc (ceux qui auraient le m√™me r√©sultat de hachage). ¬ª 

### 7. Multi-Hachage

Filtre de Bloom : bas√© sur sur plusieurs fonctions de hachage.

* On construit le filtre de telle sorte que Bloom(h_i(m)) = 1, c‚Äôest-√†-dire que si on applique le filtre de Bloom √† toutes les fonctions de hachage h_i (appliqu√© √† l‚Äô√©l√©ment m), on aura 1.
* Comme √ßa, si on veux savoir si un autre √©l√©ment m' est pr√©sent, on fait Bloom(h_i(m‚Äô))
    * si c‚Äôest != 1, alors on est sur qu‚Äôil est pas pr√©sent (pas de faux-n√©gatif)
    * si c‚Äôest = 1, alors on esp√®re qu‚Äôil est pr√©sent (possible faux-positifs)
* Bonne explication : http://bioinfo-fr.net/filtre-de-bloom



## Semaine 3 : Ex√©cution et optimisation

### 1. Introduction

* Requ√™te d√©clarative : ne dit pas comment calculer le r√©sultat.
* Plan d‚Äôex√©cution : le programme qui ex√©cute la requ√™te. Arbre constitu√© d‚Äôop√©rateurs 
* Optimisation de requ√™tes : √† chaque √©tapes, le syst√®me a le choix entre plusieurs d√©cisions (plan d‚Äôex√©cution logique et physique)

### 2. R√©√©criture alg√©brique

* Commutativit√© des jointures R ‚ãà S ‚â° S ‚ãà R
* On cr√©e comme √ßa des expressions √©quivalentes pour une m√™me requ√™te
* On ne peut pas explorer tout l‚Äôespace des expressions √©quivalentes ‚Äî> utilisation d‚Äôheuristique
    * Heuristique classique : r√©duire la taille des donn√©es
    * Filtrage des nuplets par s√©lections
    * Simplification par des projections
    * ‚Äî> S√©lection et projections le plus t√¥t possible
 
![propriete-algebrique](/downloads/bdd-propriete-algebrique.png "Propri√©t√©s alg√©briques")

### 3. Op√©rateurs

* Un plan d‚Äôex√©cution est un arbre constitu√© d‚Äôop√©rateurs √©changeants des flux de donn√©es
* Les op√©rateurs :
    * ont une forme g√©n√©rique (it√©rateur)
    * fournissent une t√¢che sp√©cialis√©e
    * peuvent √™tre bloquant ou non
* Mode mat√©rialisation : un op√©rateur calcule son r√©sultat et le transmet
    * Consomme de la m√©moire
    * Temps de latence
* Mode pipelinage : le r√©sultat est produit √† la demande
    * Plus de stockage interm√©diaire
    * Latence minimum
* On ne peut pas traiter tous les op√©rateurs en pipelinage s‚Äôils sont bloquants :
    * Exemple : `select min(date) from T`
    * `min` oblige a parcourir toute la table
* Temps de r√©ponse : temps pour obtenir le premier nuplet
* Temps d'ex√©cution : temps pour obtenir tous les nuplets

### 4. Plans d‚Äôex√©cution

* Un op√©rateur est un it√©rateur. Trois fonctions :
    * open : initialise les ressources et positionne le curseur
    * next : ram√®ne l‚Äôenregistrement courant et se place sur le suivant
    * close : lib√®re les ressources 
* It√©rateurs source et produit
* Exemple d‚Äôop√©rateur :
    * *FullScan* (voir ch3) : parcours s√©quentiel de la table
    * *IndexScan* (Arbre-B) : parcours d‚Äôun index
    * *DirectAccess* : acc√®s par adresse √† un nuplet
    * *Filter* : test de la condition
    * Utiliser ou pas l‚ÄôIndex ? Des fois c‚Äôest moins int√©ressant, quand les donn√©es sont fractionn√©es sur plusieurs blocs.

### 5. Tri et hachage

* Deux nouveaux op√©rateurs : tri et hachage.
* Tri : op√©rateur bloquant (donc co√ªteuse)
    * Utilis√© pour les algos de jointure (*sort/merge*)
    * l‚Äô√©limination des doublons (*clause distinct*)
    * les op√©ration de regroupement (*group by*)
    * les *order by*
* Tri-fusion (externe) (= mergesort). Le tri se fait en phase de open, c√†d avant le *next* (fusion).
    * Cas favorable : on charge tout dans la RAM et on fait un *quicksort*
    * Cas non-favorable : on lit un fragment, on trie (en RAM, avec *quicksort*), on stock ‚Äî> N fragments tri√©s qu‚Äôon va fusionner. Pour la fusion, on place un curseur au d√©but de chaque fragment, on compare et on prend la plus petite.

### 6. Algorithmes de jointure

* Un nouvel op√©rateur : jointure
* Type de requ√™te : `select a ... from T1, T2 ... where T1.x = T2.Y ... order by ...`
* Jointure avec index :
    * Boucle imbriqu√©es index√©es
    * Plus courante : naturellement sur les clefs primaires/√©trang√®res
    * Fonctionne en mode pipeline
    * *FullScan* sur la table de gauche, *IndexScan* sur la table de droite
* Jointure sans index :
    * Boucle imbriqu√©es (non index√©es) : on teste toutes les solutions possibles. Co√ªt quadratique.
    * Jointure par hachage. Si tient en m√©moire ‚Äî> joinlist. Sinon, on d√©coupe les deux tables en *k* fragments (qui tiennent en m√©moire) avec la m√™me fonction de hachage.

### 7. Optimisation

* Les jointures sont commutatives -> il faut mettre la table avec la clef primaire index√©e √† droite

TP
La s√©lectivit√© (nombre de nuplets s√©lectionn√©s) diminue puisque il y a plus de films apr√®s 1980 qu'apr√®s 2015. Du coup Postgres a d√©termin√© qu'un parcours s√©quentiel devenait pr√©f√©rable. Cela illustre un des aspects vus en cours: **un index n'est valable que quand on s√©lectionne une faible partie des donn√©es**. Vous pouvez varier l'ann√©e et regarder celle qui induit un changement de plan d‚Äôex√©cution.

## Semaine 4 : Contr√¥le d‚Äôacc√®s

### 1. Introduction

S√©curit√© d‚Äôacc√®s √† l‚Äôinformation.

* Int√©r√™t √©vident √† attaquer les BDD pour d√©rober des donn√©es structur√©es de grande qualit√©
* Attaquants : pirate, service de renseignement, h√©bergeur ou utilisateurs

M√©canisme de d√©fenses :

* Authentification
* Protection des communication
* Contr√¥le d‚Äôacc√®s
* Chiffrement des donn√©es
* Audit
* Contr√¥le d‚Äôusage
* R√©tention limit√©e des donn√©es
* Anonymisation des donn√©es
* L√©gislation

Contr√¥le d‚Äôacc√®s :

* Qui, est autoriser √† faire quoi, sur quelles donn√©es, dans quelles conditions.

### 2. Mod√®le de contr√¥le d'acc√®s discr√©tionnaire (DAC)

* Par d√©faut, tout est interdit.
* Le cr√©ateur d‚Äôun objet est le propri√©taire de cet objet
* Il fixe la politique de contr√¥le d‚Äôacc√®s. Certaines permissions sont transf√©rables.
* Mod√®le d√©centralis√© : souple, mais difficile √† administrer
* Les droits sont repr√©sent√©s sous forme de matrice : *Capacity List* ou *Access Control List*
* Commande `GRANT‚Ä¶  (ON‚Ä¶  TO‚Ä¶ )` : donne des droits
* Commande `REVOKE‚Ä¶  (ON‚Ä¶  FROM‚Ä¶ )` : retire des droits.
    * `CASCADE` : retire les droits en cascade
    * `RESTRICT` : retire les droits pas en cascade
* Les requ√™tes sont faites sur des vues (pas sur la table).

### 3. Mod√®le de contr√¥le d'acc√®s bas√© sur les r√¥les (RBAC)

* Les acc√®s des utilisateurs sont g√©r√©s en fonction de leur r√¥le organisationnel
* Gestion des droits facilit√©e
* Commande `CREATE ROLE` : cr√©ation d‚Äôun nouveau r√¥le
* Commande `DROP ROLE` : suppression d‚Äôun r√¥le
* Commande `SET ROLE` : activation d‚Äôun r√¥le pendant une session
* `GRANT` : fonctionne toujours
* On peut faire h√©riter des r√¥les (hi√©rarchie organisationnelle ou sp√©cialisation)
* On peut ajouter des contraintes (utilisateur/r√¥le, session/r√¥le ou r√¥le/permission)
* Depuis 2010, ABAC : *Attribute Based Access Control*

### 4. Mod√®le de contr√¥le d'acc√®s obligatoire (MAC)

* Limites du DAC et du RBAC : risque de cheval de Troie
* Cloisonnement vertical (niveaux de s√©curit√© hi√©rarchique) et horizontal (DRH, DAF, ‚Ä¶)
* Classe d‚Äôacc√®s : combinaison d‚Äôun niveau de s√©curit√© et d‚Äôune cat√©gorie
    * Niveau de s√©curit√© pour un objet : classification
    * Niveau de s√©curit√© pour un utilisateur : niveau d‚Äôaccr√©ditation (clearance)
* Deux r√®gles pour la d√©cision d‚Äôacc√®s : 
    * *No read up* : exemple, si on peut lire ¬´ confidentiel ¬ª, on peut pas lire ¬´ top secret ¬ª
    * *No write down* : exemple, si j‚Äôai acc√®s √† ¬´ top secret ¬ª, je peux pas envoyer des donn√©es dans ¬´ confidentiel ¬ª
* Oracle Label Security : level, compartment et group
* Pour acc√©der √† une donn√©es :
    * user.level >= data.level
    * data.compartement ‚äÜ user.compartment
    * user.group ‚äÜ data.group

## Semaine 5 : Reprise sur panne

### 1. Introduction

* Panne l√©g√®re : affecte la RAM, pas les disques
* Panne lourde : affecte un disque
* Garantie :
    * Durabilit√© et atomicit√© : apr√®s un commit toutes les modifications de la transaction deviennent permanentes
    * Recouvrabilit√© et atomicit√©: tant qu‚Äôun `commit` n‚Äôa pas eu lieu, on doit pouvoir annuler par un rollback.
* Pour garantir un `commit`, les donn√©es modifi√©s doivent √™tre sur le disque (image apr√®s)
* Pour garantir un `rollback`, les donn√©es avant modification doivent √™tre sur le disque (image avant)
* √âtat de la base : ensemble des transactions valid√©es ‚Äî> doit toujours √™tre sur le disque.

### 2. Lectures et √©critures, buffer et disque

* En lecture, quand la m√©moire est pleine, g√©n√©ralement on fait de la LRU (*Least Recently Used*)
* En √©criture, le bloc est modifi√© dans le *buffer* (image apr√®s), pas directement sur le disque (image avant).
* Plusieurs modes de synchronisation entre *buffer* et disque :
    * Mise √† jour imm√©diate : image avant √©cras√©e, √©criture al√©atoire
    * Mise √† jour diff√©r√©e : mise √† jour effectu√©e apr√®s le commit ‚Äî> image avant pr√©serv√©e, risque de surcharger le buffer.
    * Mise √† jour opportuniste : mise √† jour effectu√©e au meilleur moment (quand le disque est peu actif par exemple) ‚Äî> plus courant (meilleures performances), une partie de l‚Äôimage avant est √©cras√©e.

### 3. Premi√®re approche

* Panne l√©g√®re (RAM perdue)
* M√†J opportuniste : recouvrabilit√© non garantie
* M√†J imm√©diate : recouvrabilit√© non garantie
* M√†J diff√©r√©e : recouvrabilit√© non garantie (si panne pendant l‚Äô√©criture juste apr√®s le commit)
* Il faut donc avoir sur le disque l‚Äôimage avant et l‚Äôimage apr√®s ‚Äî> journal des transactions

### 4. Le journal des transactions

* On √©crit s√©quentiellement dans le journal de transaction (ou *log*)
* Le *log* a son propre buffer
* On n‚Äôefface jamais un enregistrement du *log*
* La base et son buffer sont en √©criture opportuniste
* Le *log* et son *buffer* sont en √©criture imm√©diate
* Contenu du *log* : toutes les instructions de M√†J (y compris ancienne et nouvelle valeurs)
* Au `commit`, on force l‚Äô√©criture des modifications du *log*. La transaction est valid√©e quand le `commit` est √©crit dans le *log*.
* Pour le rollback, on annule l‚Äô√©criture de blocs sur le disque, car on a la trace dans le log des modifications non valid√©e (*write-ahead logging*)

### 5. Algorithmes de reprise sur panne

* Panne l√©g√®re (√©criture opportuniste) : des modifications valid√©es pas dans la base, des modifications non valid√©es dans la base
* Refaire (*redo*) les transactions valid√©s et d√©faire (*undo*) les transactions en cours
* On regarde la liste des transactions valid√©es L_v (commit dans le log) et annul√©es L_a (pas de commit).
* UNDO : Dans l‚Äôordre inverse d‚Äôex√©cution, on prend chaque transaction de L_a et on remplace la `new_val` par `old_val`.
* REDO : Dans l‚Äôordre d‚Äôex√©cution, on prend chaque transaction de L_v et on remplace la `old_val` par `new_val`.
* Algo de reprise : tous les undo, puis tous les redo.
* Pour ne pas tous se retaper depuis la cr√©ation de la base √† chaque panne, on a des *checkpoints* o√π on √©crit sur disque tous les blocs modifi√©s. Les transactions ayant eu lieu avant un *checkpoint* sont valid√©es, pas besoin de les consid√©rer pour la reprise.

### 6. Pannes de disque

* Solution : la r√©plication
* L‚Äô√©tat de la base est √† la fois dans le *log* et dans le fichier de la base + *buffer*.
* Il faut donc que le log et la base soient sur deux disques diff√©rents
* S i panne du disque de la base : on reconstruit avec le log et on utilise des sauvegardes pour pas avoir √† tous se retaper et garder un *log* super long.
* Si panne du disque du *log* : on fait un *checkpoint*, on arr√™te tout et on red√©marre (seulement si M√†J diff√©r√©e). Mais s‚Äôil y a une panne l√©g√®re, on est niqu√© ! Du coup, on peut r√©pliquer le *log*.


## Semaine 6 : Bases de donn√©es distribu√©es

### 1. Introduction

* Les donn√©es sont souvent distribu√©es dans plusieurs SGBD et/ou plusieurs base de donn√©es.
* Un syst√®me distribu√© est une application qui coordonne les actions de plusieurs ordinateurs pour r√©aliser une t√¢che particuli√®re.
* Une base de donn√©es distribu√©s : une grande quantit√© de donn√©es r√©sidant sur plusieurs machines.
* Tout doit √™tre transparent pour l‚Äôutilisateur : OSEF de la localisation, du r√©seau/syst√®me, de la fragmentation ou de la r√©plication
* Avantages : meilleures performances, possibilit√© d‚Äôint√©gration de plusieurs BDD d‚Äôorigine diff√©rente, r√©plication des donn√©es.
* Inconv√©nients : complexit√©, absence de standard, incoh√©rences

### 2. Diff√©rentes architectures

* Mono-machine : pas de distribution
* Architecture client-serveur : client (application, GUI) et serveur (gestion des requ√™tes, transactions, pannes, etc.)
* Architecture 3 niveaux (*3-tier*) : client (navigateur web), interm√©diaire (application, communique avec le SGBD), serveur (BDD)
* Typologie : h√©t√©rog√©n√©it√© des SGBD locaux
* Typologie : degr√© d‚Äôautonomie (d‚Äôint√©gration forte √† autonomie forte)
* La m√©diation : fait le lien entre l‚Äôapplication et les adapteurs des diff√©rents SGBD

### 3. Fragmentation

* Deux types de fragmentation : horizontale et verticale
* Correspond aux deux types de stockage : par ligne (nuplet) et par colonne
* Stockage en ligne : exemple MySql, lecture/√©criture rapide de nuplets, transactionnel
* Stockage en colonne : exemple Google Big Table, lecture/√©criture rapide d‚Äôattributs, excellente compression, d√©cisionnel
* Obligation : pas de perte d‚Äôinformation
* Pr√©f√©rable : pas de redondance

### 4. Optimisation de requ√™te

* Nouveaux plans d‚Äôex√©cutions d√ª √† l‚Äôarchitecture distribu√©e
* Centralisation brutale : on envoie tout
* Solution optimis√©e : on envoie qu‚Äôune partie des donn√©es
* Les probl√®mes sont s√©par√©s pour simplifier : analyse syntaxique, localisation, optimisation globale (minimisation des communications), optimisation locale (minimisation des I/O et des calculs) 

### 5. R√©plication

* La r√©plication est utilis√©e principalement pour la fiabilit√©.
* Une autre raison : les performances
* *Trade-off* : requ√™tes vs mises-√†-jour

### 6. Concurrence

* Sans r√©plication, la notion de s√©rialisabilit√© s‚Äô√©tend, le verrouillage √† deux phases aussi. Plus dur de d√©tect√© les *deadlocks* ‚Äî> *timeout*.
* Si r√©plication, deux m√©thodes :
    * R√©plication asynchrone (incorrecte, pas de coh√©rence)
    * Technique ROWA (*read-once/write all*) : lecture sur une des copies, √©criture sur toutes les copies.

### 7. Conclusion : cinq tendances

* *Cloud* : appli et donn√©es dans le cloud
* NoSQL : pour les applications ¬´ extr√™mes ¬ª : applications transactionnelles (millions de transactions pas seconde) ou d√©cisionnelles (analyse de t√©raoctets de donn√©es). Langage plus simple, mod√®le plus simple, moins universel.
* Pair-√†-pair : chaque machine est √† la fois un serveur et un client.
* Big data : de plus en plus de donn√©es, analyse des donn√©es (*machine learning*), calcul massivement parall√®le (Hadoop), syst√®mes NoSQL
* Base de donn√©es en m√©moire : des serveurs avec tellement de RAM que les BDD tiennent dedans (*blade server 100 cores, 10 Tb de m√©moire*).
